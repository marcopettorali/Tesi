#!/usr/bin/python

from http.server import BaseHTTPRequestHandler, HTTPServer
import socketserver
import os
from os import curdir, sep
import cgi
import numpy
import cv2
import sys
sys.path.insert(0, "../../ncapi2_shim")
import mvnc_simple_api as mvnc

PORT_NUMBER = 8080
SOGLIA = 60
NUM_FOTO = 20
immagine = ' '
graph = ' '
camera = ' '
dim=(300,300)

#Etichette riconosciute dal sistema (tradotte in italiano):
LABELS = ('sfondo',
          'aereoplano', 'bicicletta', 'uccello', 'barca',
          'bottiglia', 'autobus', 'automobile', 'gatto', 'sedia',
          'mucca', 'tavolo, scrivania', 'cane', 'cavallo',
          'motocicletta', 'persona', 'pianta',
          'pecora', 'divano, poltrona', 'treno', 'schermo')

def run_inference(image_to_classify, ssd_mobilenet_graph):

    resized_image = preprocess_image(image_to_classify)
    ssd_mobilenet_graph.LoadTensor(resized_image.astype(numpy.float16), None)

    output, userobj = ssd_mobilenet_graph.GetResult()
    num_valid_boxes = int(output[0])
    ret_str = ' '
    for box_index in range(num_valid_boxes):
            base_index = 7+ box_index * 7
            if (not numpy.isfinite(output[base_index]) or
                    not numpy.isfinite(output[base_index + 1]) or
                    not numpy.isfinite(output[base_index + 2]) or
                    not numpy.isfinite(output[base_index + 3]) or
                    not numpy.isfinite(output[base_index + 4]) or
                    not numpy.isfinite(output[base_index + 5]) or
                    not numpy.isfinite(output[base_index + 6])):
                print('il box all\'indice: ' + str(box_index) + ' ha dati di output non definiti, ignoro')
                continue

            x1 = max(0, int(output[base_index + 3] * image_to_classify.shape[0]))
            y1 = max(0, int(output[base_index + 4] * image_to_classify.shape[1]))
            x2 = min(image_to_classify.shape[0], int(output[base_index + 5] * image_to_classify.shape[0]))
            y2 = min(image_to_classify.shape[1], int(output[base_index + 6] * image_to_classify.shape[1]))

            x1_ = str(x1)
            y1_ = str(y1)
            x2_ = str(x2)
            y2_ = str(y2)

            percentuale = output[base_index + 2]*100
            if(percentuale <= SOGLIA):
                continue
            overlay_on_image(image_to_classify, output[base_index:base_index + 7])
            ret_str = ret_str + ('Oggetto n.' + str(box_index) + ' : ' + LABELS[int(output[base_index + 1])] + '<br>' +
			         'Attendibilit√†: ' + str(round(output[base_index + 2]*100,2)) + '%<br>' +
				 'Angolo in alto a sx: (' + x1_ + ', ' + y1_ + ')  Angolo in basso a dx: (' + x2_ + ', ' + y2_ + ')<br><br>')
            return ret_str

def overlay_on_image(display_image, object_info):

    source_image_width = display_image.shape[1]
    source_image_height = display_image.shape[0]

    base_index = 0
    class_id = object_info[base_index + 1]
    percentage = int(object_info[base_index + 2] * 100)

    label_text = LABELS[int(class_id)] + " (" + str(percentage) + "%)"
    box_left = int(object_info[base_index + 3] * source_image_width)
    box_top = int(object_info[base_index + 4] * source_image_height)
    box_right = int(object_info[base_index + 5] * source_image_width)
    box_bottom = int(object_info[base_index + 6] * source_image_height)

    box_color = (255, 128, 0)
    box_thickness = 2
    cv2.rectangle(display_image, (box_left, box_top), (box_right, box_bottom), box_color, box_thickness)

    label_background_color = (125, 175, 75)
    label_text_color = (255, 255, 255)

    label_size = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]
    label_left = box_left
    label_top = box_top - label_size[1]
    if (label_top < 1):
        label_top = 1
    label_right = label_left + label_size[0]
    label_bottom = label_top + label_size[1]
    cv2.rectangle(display_image, (label_left - 1, label_top - 1), (label_right + 1, label_bottom + 1),
                  label_background_color, -1)

    cv2.putText(display_image, label_text, (label_left, label_bottom), cv2.FONT_HERSHEY_SIMPLEX, 0.5, label_text_color, 1)

def preprocess_image(src):

    NETWORK_WIDTH = 300
    NETWORK_HEIGHT = 300
    img = cv2.resize(src, (NETWORK_WIDTH, NETWORK_HEIGHT))

    img = img - 127.5
    img = img * 0.007843
    return img

class HTTPHandler(BaseHTTPRequestHandler):

	def do_GET(self):

		global immagine
		if self.path=="/":
			self.path="/image-classifier.html"

		try:
			sendReply = False
			if self.path.endswith(".html"):
				mimetype='text/html'
				sendReply = True
			if self.path.endswith(".css"):
				mimetype='text/css'
				sendReply = True

			if "/get-image" in self.path:

				image = None
				oggetti = None

				for i in range(NUM_FOTO):
					print("Fotogramma: " + str(i))
					img_ret, image = camera.read()
					oggetti = run_inference(image, graph)
					if(not oggetti == None and "persona" in oggetti):
						#esci per visualizzare l'immagine raffigurante un umano
						break

				print (oggetti)
				html_colore_esito = "red"
				html_esito_persona_presente = "Macchinario non riavviato: persona presente"

				if(oggetti == None or not "persona" in oggetti):
					html_colore_esito = "green"
					html_esito_persona_presente = "Macchinario riavviato"
					#inserire qui operazione di riavvio macchina

				f = '''<!DOCTYPE html>
					<html lang="en">
					  <head>
						<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
						<title>Riavvio Macchinario</title>
						<meta name="author" content="Marco Pettorali">
					  </head>
					  <body>
						<h1>Riavvio Macchinario</h1>
						<img style = "float: left;" src="frame.jpg">
						<h1 style = "color: {}">{}</h1>
						<p>{}</p>
						<form method="get" action="get-image">
							<button type="submit">Ritenta avvio macchina</button>
						</form>
						</body>
					</html>
				'''.format(html_colore_esito, html_esito_persona_presente, oggetti)
				retval, jpg = cv2.imencode('.jpg', image)
				immagine = jpg.tobytes()
				self.send_response(200)
				self.send_header('Content-type', 'text/html')
				self.end_headers()
				self.wfile.write(bytes(f, 'utf-8'))
				return
			if self.path.endswith(".jpg"):
				mimetype='image/jpg'
				sendReply = True
				self.send_response(200)
				self.send_header('Content-type',mimetype)
				self.end_headers()
				self.wfile.write(immagine)
				return
			if sendReply == True:
				f = open(curdir + sep + self.path) 
				self.send_response(200)
				self.send_header('Content-type',mimetype)
				self.end_headers()
				self.wfile.write(bytes(f.read(), "utf-8"))
				f.close()
			return
		except IOError:
			self.send_error(404,'File Not Found: %s' % self.path)	
			
try:
	server = HTTPServer(("", PORT_NUMBER), HTTPHandler)
	print ('Started httpserver')
	devices = mvnc.EnumerateDevices()
	#apro lo stick Movidius una volta sola all'avvio del servizio
	if len(devices) == 0:
        	print('No devices found')
        	quit()
	device = mvnc.Device(devices[0])
	device.OpenDevice()
	with open('graph', mode='rb') as f:
		graph_in_memory = f.read()
		graph = device.AllocateGraph(graph_in_memory)
	camera = cv2.VideoCapture(0)
	camera.set(cv2.CAP_PROP_BUFFERSIZE, 1)
	server.serve_forever()
except KeyboardInterrupt:
	print ('Chiudo il servizio')
	server.socket.close()
	#chiudo lo stick Movidius quando tutte le elaborazioni sono terminate
	graph.DeallocateGraph()
	device.CloseDevice()
	del(camera)
